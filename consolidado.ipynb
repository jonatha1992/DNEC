{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importante \n",
    "\n",
    "* Tener en cuenta bajadas de Procedimientos, Personas Armas, Divisas , vehiculos (secuestrados, ministerio), Narcotrafico general,Objetos y pegar en la carpeta bajadas de fecha del primero del 1 del mes en informar hasta fecha del informe "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "source": [
    "### Importacion de librerias\n",
    "importacion de libreias para tranformacion de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parametros\n",
    "Coloco los parametros a tener en cuenta para donde se encuentra los archivos de bajada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "LUGARES_CATALOGADOS= {\n",
    "                    \"SECTOR RESTRINGIDO\":\t\"SECTOR DE SEGURIDAD RESTRINGIDA AEROPORTUARIA\",\n",
    "                    \"SECTOR PUBLICO\"\t:\"INSTALACIONES DE ACCESO AL PUBLICO GENERAL\",\n",
    "                    \"PERIMETRO DE JURISDICCION\":\t\"PERIMETRO AEROPORTUARIO\",\n",
    "                    \"FUERA DE JURISDICCION\":\t\"DESPLIEGUE\",\n",
    "                    \"TRANSPORTE PUBLICO\": \"TRANSPORTE PUBLICO\",\n",
    "                    \"S/D\": \"S/D\"\n",
    "}\n",
    "\n",
    "UNIDADES_MUNICIPIOS = {\n",
    "    \"EZE\": \"JOSÉ M. EZEIZA\",\n",
    "    \"AER\": \"COMUNA 14\",\n",
    "    \"SFO\": \"SAN FERNANDO\",\n",
    "    \"BHI\": \"BAHÍA BLANCA\",\n",
    "    \"MDP\": \"GENERAL PUEYRREDÓN\",\n",
    "    \"MDZ\": \"LAS HERAS\",\n",
    "    \"COR\": \"CAPITAL\",\n",
    "    \"JUA\": \"9 DE JULIO\",\n",
    "    \"LUI\": \"JUAN MARTÍN DE PUEYRREDÓN\",\n",
    "    \"MLG\": \"MALARGÜE\",\n",
    "    \"RAF\": \"SAN RAFAEL\",\n",
    "    \"RCU\": \"RÍO CUARTO\",\n",
    "    \"SRO\": \"CAPITAL\",\n",
    "    \"JUJ\": \"EL CARMEN\",\n",
    "    \"SAL\": \"LA CAPITAL\",\n",
    "    \"CAT\": \"VALLE VIEJO\",\n",
    "    \"LAR\": \"CAPITAL\",\n",
    "    \"SGO\": \"CAPITAL\",\n",
    "    \"TRH\": \"RÍO HONDO\",\n",
    "    \"TUC\": \"CRUZ ALTA\",\n",
    "    \"IGU\": \"IGUAZÚ\",\n",
    "    \"FSA\": \"FORMOSA\",\n",
    "    \"ROS\": \"ROSARIO\",\n",
    "    \"RCQ\": \"GENERAL OBLIGADO\",\n",
    "    \"POS\": \"CAPITAL\",\n",
    "    \"CRR\": \"CAPITAL\",\n",
    "    \"LIB\": \"PASO DE LOS LIBRES\",\n",
    "    \"PAR\": \"PARANÁ\",\n",
    "    \"RES\": \"SAN FERNANDO\",\n",
    "    \"SVO\": \"LA CAPITAL\",\n",
    "    \"BAR\": \"BARILOCHE\",\n",
    "    \"TRE\": \"RAWSON\",\n",
    "    \"NEU\": \"CONFLUENCIA\",\n",
    "    \"CAL\": \"LAGO ARGENTINO\",\n",
    "    \"CHP\": \"LÁCAR\",\n",
    "    \"CRV\": \"ESCALANTE\",\n",
    "    \"PMY\": \"BIEDMA\",\n",
    "    \"ESQ\": \"FUTALEUFÚ\",\n",
    "    \"GAL\": \"GÜER AIKE\",\n",
    "    \"GDE\": \"RÍO GRANDE\",\n",
    "    \"USU\": \"USHUAIA\",\n",
    "    \"VIE\": \"ADOLFO ALSINA\",\n",
    "    \"RG4\": \"-\",\n",
    "}\n",
    "\n",
    "PROVINCIAS = {\n",
    "    \"C.A. BUENOS AIRES\": \"CIUDAD AUTONOMA DE BUENOS AIRES\",\n",
    "    \"BUENOS AIRES\": \"BUENOS AIRES\",\n",
    "    \"SANTA CRUZ\": \"SANTA CRUZ\",\n",
    "    \"SANTA FE\": \"SANTA FE\",\n",
    "    \"MENDOZA\": \"MENDOZA\",\n",
    "    \"TUCUMÁN\": \"TUCUMAN\",\n",
    "    \"TIERRA DEL FUEGO\": \"TIERRA DEL FUEGO ANTARTIDA E ISLAS DEL ATLANTICO SUR\",\n",
    "    \"SALTA\": \"SALTA\",\n",
    "    \"NEUQUÉN\": \"NEUQUEN\",\n",
    "    \"CÓRDOBA\": \"CORDOBA\",\n",
    "    \"LA PAMPA\": \"LA PAMPA\",\n",
    "    \"RÍO NEGRO\": \"RIO NEGRO\",\n",
    "    \"CATAMARCA\": \"CATAMARCA\",\n",
    "    \"MISIONES\": \"MISIONES\",\n",
    "    \"SAN JUAN\": \"SAN JUAN\",\n",
    "    \"CORRIENTES\": \"CORRIENTES\",\n",
    "    \"CHUBUT\": \"CHUBUT\",\n",
    "    \"FORMOSA\": \"FORMOSA\",\n",
    "    \"JUJUY\": \"JUJUY\",\n",
    "    \"SANTIAGO DEL ESTERO\": \"SANTIAGO DEL ESTERO\",\n",
    "    \"LA RIOJA\": \"LA RIOJA\",\n",
    "    \"CHACO\": \"CHACO\",\n",
    "    \"ENTRE RÍOS\": \"ENTRE RIOS\",\n",
    "    \"SAN LUIS\": \"SAN LUIS\"\n",
    "}\n",
    "\n",
    "\n",
    "UNIDADES= {\n",
    "        \"DROPA I\": \"UR1\"\n",
    "}\n",
    "\n",
    "PERSONAL = {    \n",
    "    \"DENUNCIA\": 4,\n",
    "    \"CONTROL PREVENTIVO\": 6,\n",
    "    \"PATIO VALIJAS\": 6,\n",
    "    \"ALLANAMIENTO\" :8,\n",
    "}\n",
    "\n",
    "SCANNER = {\n",
    "    \"DENUNCIA\": 4,\n",
    "    \"CONTROL PREVENTIVO\": 6,\n",
    "    \"PATIO VALIJAS\": 6,\n",
    "    \"ALLANAMIENTO\" :8,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de Datos\n",
    "### Leer base de datos\n",
    "\n",
    "leer la base de datos \"data/Base_informada\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leer_excel_a_df(worksheet):\n",
    "    data = []\n",
    "    titulos = [worksheet.cell(row=3, column=col).value for col in range(2, worksheet.max_column + 1)]\n",
    "    for row in worksheet.iter_rows(min_row=4, min_col=2, max_col=worksheet.max_column, values_only=True):\n",
    "        data.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(data, columns=titulos)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_base_informada = load_workbook(\"data/BASE_PROCESADO.xlsx\")\n",
    "hoja = df_base_informada['GEOG. PROCEDIMIENTO']\n",
    "\n",
    "df_base_informada = leer_excel_a_df(hoja)\n",
    "\n",
    "conteo_base_datos = df_base_informada['ID_OPERATIVO'].value_counts()\n",
    "conteo_acumulado  = conteo_base_datos.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedimientos\n",
    "### Funciones \n",
    "declaraciones de funciones procesar cada celda y columna del informe del sigipol como de operaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "contador_global_sigipol = {}\n",
    "def generar_codigo_sigipol(row):\n",
    "    id_operativo = row['ID_OPERATIVO']\n",
    "    if id_operativo not in contador_global_sigipol:\n",
    "        contador_global_sigipol[id_operativo] = 0\n",
    "    contador_global_sigipol[id_operativo] += 1\n",
    "    contador = contador_global_sigipol[id_operativo]\n",
    "    return id_operativo + \"-(\" + str(contador) + \")\"\n",
    "\n",
    "def generar_codigo_sigipol_2(row):\n",
    "        id_operativa = row['']\n",
    "        if id_operativa in conteo_acumulado:\n",
    "            conteo_acumulado[id_operativa] += 1\n",
    "        else:\n",
    "            conteo_acumulado[id_operativa] = 1\n",
    "        id_procedimiento = f\"{id_operativa}-({conteo_acumulado[id_operativa]})\"\n",
    "        print (\"id_procedimiento: \" + id_procedimiento )\n",
    "        return id_procedimiento\n",
    "\n",
    "def generar_uid_sigpol(row):\n",
    "        ursa = row['URSA']\n",
    "        uosp = row['UOSP']\n",
    "        numero_parte = row['NUMERO_PARTE']\n",
    "        anio = row['ANIO_PARTE']\n",
    "        return ursa +\"-\"+ uosp + \"-\"+ numero_parte+\"-\" + numero_parte + \"-\"+anio\n",
    "    \n",
    "def generar_uid_operaciones(row):\n",
    "        id_operativa = row['ID_OPERATIVO']\n",
    "        if id_operativa in conteo_acumulado:\n",
    "            conteo_acumulado[id_operativa] += 1\n",
    "        else:\n",
    "            conteo_acumulado[id_operativa] = 1\n",
    "        id_procedimiento = f\"{id_operativa}-({conteo_acumulado[id_operativa]})\"\n",
    "        print (\"id_procedimiento: \" + id_procedimiento )\n",
    "        return id_procedimiento\n",
    "        \n",
    "def procesar_descripcion(row):\n",
    "    tipo = row['TIPO_PROCEDIMIENTO']\n",
    "    if tipo == \"DENUNCIA\":\n",
    "        return \"DENUNCIA POLICIAL\"\n",
    "    elif tipo == \"CONTROL PREVENTIVO\":\n",
    "        return f\"CONTROL PREVENTIVO - {procesar_lugar(row)}\"\n",
    "    elif tipo == \"ORDEN DE ALLANAMIENTO\":\n",
    "        return \"ORDEN DE ALLANAMIENTO\"\n",
    "    elif tipo == \"ORDEN DE ALLANAMIENTO / DETENCIÓN\":\n",
    "        return \"ORDEN DE ALLANAMIENTO\"\n",
    "    else:\n",
    "        return \"OTRO MANDATO JUDICIAL\"\n",
    "\n",
    "def procesar_tipo(row):\n",
    "    tipo = row['TIPO_PROCEDIMIENTO']\n",
    "    if pd.isna(tipo):\n",
    "        return \"\"\n",
    "    elif tipo == \"DENUNCIA\"  or tipo == \"CONTROL PREVENTIVO\" :\n",
    "        return \"ORDEN POLICIAL\"\n",
    "    else:\n",
    "        return \"ORDEN JUDICIAL\"\n",
    "    \n",
    "def procesar_provincia(row):\n",
    "    provincia = row['PROVINCIA']\n",
    "    if pd.isna(provincia):\n",
    "        return \"\"\n",
    "    return PROVINCIAS.get(provincia, provincia)\n",
    "    \n",
    "def procesar_municipio(row):\n",
    "    unidad = row['UOSP']\n",
    "    if pd.isna(unidad):\n",
    "        return \"\"\n",
    "    return UNIDADES_MUNICIPIOS.get(unidad, unidad)\n",
    "\n",
    "def procesar_lugar(row):\n",
    "    lugar = row['LUGAR_CATALOGADO_NIVEL_1']\n",
    "    return  LUGARES_CATALOGADOS[lugar]\n",
    "\n",
    "def procesar_direccion(row):\n",
    "    lugar = row['LUGAR_CATALOGADO_NIVEL_1']\n",
    "    ciudad = row['CIUDAD']\n",
    "    if lugar == \"FUERA DE JURISDICCION\" and ciudad == \"ROSARIO\":\n",
    "        return \"-\"\n",
    "    elif lugar == \"FUERA DE JURISDICCION\":\n",
    "        return str(row['CALLE']) + \" \" + str(row['NUMERO']) + \", \" + str(row['CIUDAD']) + \" - \" + str(row['PARTIDO'])\n",
    "    else:\n",
    "        return \"-\"\n",
    "    \n",
    "def controlar_estado (row):\n",
    "    ursa = row['URSA'] \n",
    "    unidad = row['UOSP'] \n",
    "    estado = row['ESTADO_PARTE'] \n",
    "    if pd.isna(unidad)  and ursa == 'RG4' and estado == 'NO DISPONIBLE ESTADISTICA':\n",
    "        return  \"DISPONIBLE ESTADISTICA\"\n",
    "    else:\n",
    "        return estado \n",
    "    \n",
    "\n",
    "\n",
    "def procesar_causa_judicial(row):\n",
    "    # Obtener la causa y asegurarse de que no sea None\n",
    "    causa = row.get('CAUSAJUDICIALNUMERO', '')\n",
    "    if causa is None or pd.isna(causa):\n",
    "        causa = ''\n",
    "\n",
    "    tipo = str(row.get('TIPO_CAUSA_INTERNA', '')).strip()\n",
    "    causa_int = str(row.get('CAUSA_INTERNA_NUMERO', '')).strip()\n",
    "\n",
    "\n",
    "    # Verificar si la causa está vacía o contiene ciertos valores\n",
    "    if causa in [\"\", \"S/D\", \"A/S\", \"N/C\"]:\n",
    "        # Manejar valores faltantes asignando un valor predeterminado al resultado\n",
    "        resultado = f\"{tipo}-{causa_int}\".replace(\"--\", \"-\")\n",
    "        return resultado\n",
    "\n",
    "    # Lista de prefijos que se quieren eliminar (sin importar mayúsculas o minúsculas)\n",
    "    prefijos = [\"NRO\", \"N°\", \"EXPTE\", \"EXPEDIENTE\", \"EXPT\", \"N\"]\n",
    "\n",
    "    # Crear una expresión regular que busque todos los prefijos y los elimine\n",
    "    prefijos_regex = r'\\b(' + '|'.join([re.escape(prefijo) for prefijo in prefijos]) + r')\\b'\n",
    "\n",
    "    # Eliminar prefijos de la causa\n",
    "    causa = re.sub(prefijos_regex, '', causa, flags=re.IGNORECASE).strip()\n",
    "\n",
    "    # Eliminar el símbolo \"°\" si está presente\n",
    "    causa = causa.replace(\"°\", \"\").replace(\".\",\"\").replace('\"',\"\").strip()\n",
    "\n",
    "    # Utilizar una expresión regular para dividir letras seguidas de números con un guion\n",
    "    causa_str = re.sub(r'([A-Za-z]+)\\s*(\\d+)', r'\\1-\\2', causa)\n",
    "\n",
    "    # Reemplazar cualquier doble guion que haya quedado\n",
    "    causa_str = causa_str.replace(\"--\", \"-\").replace(\"---\", \"-\")\n",
    "    \n",
    "    return causa_str\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedimientos\n",
    "### Ingresar bajada de procedimiento\n",
    "\n",
    "* convierto las bajadas en el dataframe para poder manipularlos y poder hacer calculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_bajada_procedimientos = pd.read_excel('bajadas/bajada_general.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Filtrar procedimientos \n",
    "solo que esta que estan disponible en estadistica y las fechas estipuladas de información "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_bajada_procedimientos['ESTADO_PARTE'] = excel_bajada_procedimientos.apply(controlar_estado ,axis=1).copy()\n",
    "excel_bajada_procedimientos['UOSP'] = excel_bajada_procedimientos['UOSP'].fillna(excel_bajada_procedimientos['URSA'])\n",
    "excel_bajada_procedimientos['GEOREFERENCIA_X'] = excel_bajada_procedimientos['GEOREFERENCIA_X'].fillna('-')\n",
    "excel_bajada_procedimientos['GEOREFERENCIA_Y'] = excel_bajada_procedimientos['GEOREFERENCIA_Y'].fillna('-')\n",
    "\n",
    "excel_bajada_procedimientos = excel_bajada_procedimientos[\n",
    "    (excel_bajada_procedimientos['ESTADO_PARTE'] != 'NO DISPONIBLE ESTADISTICA') \n",
    "].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtros de procedimientos\n",
    "Ejecucion de funciones para la bajada de procedimientos de sigipol  tranformando los datos para que se muestren como lo requiere la DNEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procedimientos = pd.DataFrame()\n",
    "\n",
    "df_procedimientos['ID_OPERATIVO'] = excel_bajada_procedimientos.apply(procesar_causa_judicial, axis=1)\n",
    "df_procedimientos['ID_PROCEDIMIENTO'] = df_procedimientos.apply(generar_codigo_sigipol_2, axis=1)\n",
    "df_procedimientos['UNIDAD_INTERVINIENTE'] = excel_bajada_procedimientos['UOSP']\n",
    "df_procedimientos['DESCRIPCIÓN'] = excel_bajada_procedimientos.apply(procesar_descripcion, axis=1)\n",
    "df_procedimientos['TIPO_INTERVENCION'] = excel_bajada_procedimientos.apply(procesar_tipo, axis=1)\n",
    "df_procedimientos['PROVINCIA'] = excel_bajada_procedimientos.apply(procesar_provincia, axis=1)\n",
    "df_procedimientos['DEPARTAMENTO O PARTIDO'] = excel_bajada_procedimientos.apply(procesar_municipio, axis=1)\n",
    "df_procedimientos['LOCALIDAD'] = \"-\"\n",
    "df_procedimientos['DIRECCION'] = excel_bajada_procedimientos.apply(procesar_direccion, axis=1)\n",
    "df_procedimientos['LATITUD'] = excel_bajada_procedimientos['GEOREFERENCIA_Y']\n",
    "df_procedimientos['LONGITUD'] = excel_bajada_procedimientos['GEOREFERENCIA_X']\n",
    "df_procedimientos['FECHA'] = pd.to_datetime(excel_bajada_procedimientos['DENUNCIAFECHA'], errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "df_procedimientos['HORA'] = pd.to_datetime(excel_bajada_procedimientos['DENUNCIAFECHA'], errors='coerce').dt.strftime('%H:%M')\n",
    "df_procedimientos['FUERZA_INTERVINIENTE'] = \"PSA\"\n",
    "df_procedimientos['ZONA_SEGURIDAD_FRONTERAS'] = \"-\"\n",
    "df_procedimientos['PASO_FRONTERIZO'] = \"-\"\n",
    "df_procedimientos['OTRAS AGENCIAS INTERVINIENTES'] = \"-\"\n",
    "df_procedimientos['Observaciones - Detalles'] = \"-\"\n",
    "\n",
    "\n",
    "df_procedimientos = df_procedimientos[['FUERZA_INTERVINIENTE', 'ID_OPERATIVO', 'ID_PROCEDIMIENTO',\n",
    "                                     'UNIDAD_INTERVINIENTE', 'DESCRIPCIÓN', 'TIPO_INTERVENCION',\n",
    "                                     'PROVINCIA', 'DEPARTAMENTO O PARTIDO', 'LOCALIDAD', 'DIRECCION',\n",
    "                                     'ZONA_SEGURIDAD_FRONTERAS', 'PASO_FRONTERIZO', 'LATITUD', 'LONGITUD',\n",
    "                                     'FECHA', 'HORA', 'OTRAS AGENCIAS INTERVINIENTES', 'Observaciones - Detalles']]\n",
    "\n",
    "\n",
    "# df_procedimientos = df_procedimientos[~df_procedimientos['UID'].isin(df_base_informada['UID'])].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtro de procedimiento con respecto a la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rapidfuzz import fuzz\n",
    "\n",
    "# Definir un umbral de similitud\n",
    "similarity_threshold = 90\n",
    "\n",
    "# Crear una copia del DataFrame de procedimientos para filtrado\n",
    "df_filtered = df_procedimientos.copy()\n",
    "\n",
    "# Iterar sobre las filas en `df_procedimientos`\n",
    "for idx, row in df_procedimientos.iterrows():\n",
    "    # Obtener los valores de los campos a comparar de la fila actual\n",
    "    id_procedimiento = row['ID_PROCEDIMIENTO']\n",
    "    id_operativo = row['ID_OPERATIVO']\n",
    "\n",
    "\n",
    "    # Calcular el máximo de similitud entre todos los registros en `df_base_informada`\n",
    "    max_similarity = 0\n",
    "\n",
    "    for _, base_row in df_base_informada.iterrows():\n",
    "        # Calcular la similitud individual entre los campos de `df_procedimientos` y `df_base_informada`\n",
    "        similarity_id = fuzz.ratio(id_procedimiento, base_row['ID_PROCEDIMIENTO'])\n",
    "        similarity_name = fuzz.ratio(id_operativo, base_row['ID_OPERATIVO'])\n",
    "\n",
    "        # Promedio de similitud para los campos de interés\n",
    "        average_similarity = (similarity_id + similarity_name ) / 2\n",
    "\n",
    "        # Actualizar el máximo de similitud encontrado\n",
    "        max_similarity = max(max_similarity, average_similarity)\n",
    "\n",
    "    # Eliminar la fila si el promedio de similitud supera el umbral\n",
    "    if max_similarity >= similarity_threshold:\n",
    "        df_filtered = df_filtered.drop(idx)\n",
    "\n",
    "# Resulting DataFrame with rows that have less than the threshold similarity\n",
    "df_procedimientos = df_filtered.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operaciones\n",
    "### Funciones de filtro para operaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filas_diferentes(row, df_base_informada):\n",
    "    # Buscar si hay alguna fila en df_base_informada que sea idéntica en las columnas especificadas\n",
    "    match = df_base_informada[\n",
    "        (df_base_informada['ID_OPERATIVO'] != row['ID_OPERATIVO']) &\n",
    "        (df_base_informada['FECHA'] != row['FECHA']) &\n",
    "        (df_base_informada['LATITUD'] != row['LATITUD']) &\n",
    "        (df_base_informada['LONGITUD'] != row['LONGITUD'])\n",
    "    ]\n",
    "    # Si no se encuentra un match, significa que la fila es diferente\n",
    "    return match.empty\n",
    "\n",
    "def procesar_unidad (row):\n",
    "    unidad = row['UNIDAD_INTERVINIENTE']\n",
    "    return  UNIDADES.get(unidad, unidad)\n",
    "\n",
    "\n",
    "def colocar_guion_espacio(texto):\n",
    "    texto = texto.strip()\n",
    "    texto = texto.replace(\"N°\", \"\").replace(\" \", \"-\").replace(\".\", \"\")\n",
    "\n",
    "    # Manejar prefijos específicos\n",
    "    prefijos = ['OSR', 'OSL', 'OSC']\n",
    "    \n",
    "    for prefijo in prefijos:\n",
    "        if texto.upper().startswith(prefijo):\n",
    "            # Eliminar el prefijo y agregarlo nuevamente con un guion si no lo tiene\n",
    "            texto = texto[len(prefijo):].strip()\n",
    "            if not texto.startswith(\"-\"):\n",
    "                texto = prefijo + \"-\" + texto\n",
    "            if \"(\" in texto and not \"-(\" in texto:\n",
    "                texto = texto.replace(\"(\", \"-(\")\n",
    "            break\n",
    "\n",
    "    texto = re.sub(r'-+', '-', texto)\n",
    "    \n",
    "    \n",
    "    texto=  formatear_contador(texto)\n",
    "    return texto\n",
    "\n",
    "\n",
    "def formatear_contador(texto):\n",
    "    # Eliminar cualquier \"-(número)\" o \"--(número)\" al final del texto\n",
    "    texto_procesado = re.sub(r'-+\\(\\d+\\)$', '', texto)\n",
    "\n",
    "    return texto_procesado\n",
    "\n",
    "\n",
    "\n",
    "def colocar_contador (df_operaciones):\n",
    "    conteo_base_datos = df_base_informada['ID_OPERATIVO'].value_counts()\n",
    "    conteo_acumulado  = conteo_base_datos.to_dict()\n",
    "    df_ordenes_no_informadas = pd.DataFrame()\n",
    "    for index, row in df_operaciones.iterrows():\n",
    "        id_operativa = row['ID_OPERATIVO']\n",
    "        \n",
    "        # Verificar cuántas veces ha aparecido el ID_operativa en total hasta ahora (base + nuevos)\n",
    "        if id_operativa in conteo_acumulado:\n",
    "            conteo_acumulado[id_operativa] += 1\n",
    "        else:\n",
    "            conteo_acumulado[id_operativa] = 1\n",
    "        \n",
    "        nuevo_id_procedimiento = f\"{id_operativa}-({conteo_acumulado[id_operativa]})\"\n",
    "        \n",
    "        df_ordenes_no_informadas.at[index, 'ID_PROCEDIMIENTO'] = nuevo_id_procedimiento\n",
    "        \n",
    "    return df_ordenes_no_informadas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filtros de Ordenes de servicios operaciones\n",
    "Ejecucion de funciones para la planilla enviada por operaciones tranformando los datos para que se muestren como lo requiere la DNEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_bajada_operaciones = load_workbook(\"bajadas/operaciones.xlsx\")\n",
    "hoja_geog = excel_bajada_operaciones['GEOG. PROCEDIMIENTO']\n",
    "hoja_vehi = excel_bajada_operaciones['VEHI. Y PERSO. CONTROLADAS']\n",
    "\n",
    "\n",
    "df_operaciones = leer_excel_a_df(hoja_geog)\n",
    "df_operaciones = df_operaciones.dropna(subset=['ID_PROCEDIMIENTO'], how='any').copy()\n",
    "df_operaciones['ID_PROCEDIMIENTO'] = df_operaciones['ID_PROCEDIMIENTO'].apply(colocar_guion_espacio)\n",
    "df_operaciones['UNIDAD_INTERVINIENTE'] = df_operaciones.apply(procesar_unidad, axis=1)\n",
    "df_operaciones['ID_OPERATIVO'] = df_operaciones['ID_PROCEDIMIENTO'].copy()\n",
    "df_operaciones['FECHA'] = pd.to_datetime(df_operaciones['FECHA'], errors='coerce')\n",
    "\n",
    "# Aplicar la función para identificar las filas que son diferentes\n",
    "df_operaciones = df_operaciones[df_operaciones.apply(filas_diferentes, axis=1, df_base_informada=df_base_informada)].copy()\n",
    "\n",
    "\n",
    "\n",
    "df_operaciones = colocar_contador(df_operaciones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardado de informaciópn\n",
    "\n",
    "Ordeno la informacion como de la hoja de procedimientos segun el la plainilla modelo y guardo en la planilla informe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo Excel 'Planilla_informe.xlsx' modificado con éxito.\n"
     ]
    }
   ],
   "source": [
    "df_geog = pd.concat([df_operaciones, df_procedimientos])\n",
    "\n",
    "nombre_archivo_modelo = \"Planilla_modelo.xlsx\"\n",
    "nombre_archivo_informe = \"Planilla_informe.xlsx\"\n",
    "wb = load_workbook(nombre_archivo_modelo)\n",
    "ws = wb['GEOG. PROCEDIMIENTO']\n",
    "\n",
    "# Escribir los datos del DataFrame desde la fila 4\n",
    "for row_num, row in enumerate(df_geog.itertuples(index=False), start=4):\n",
    "    for col_num, value in enumerate(row, start=2):  # Comienza desde la columna B (número 2)\n",
    "        ws.cell(row=row_num, column=col_num).value = value\n",
    "\n",
    "# Guardar los cambios\n",
    "wb.save(nombre_archivo_informe)\n",
    "\n",
    "print(f\"\\nArchivo Excel '{nombre_archivo_informe}' modificado con éxito.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control de salidad de la informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función procesar_causa_judicial a la copia\n",
    "\n",
    "# # Contar cuántos casos se procesaron vs. cuántos se mantuvieron igual\n",
    "# procesados = (wb_nueva_hoja['CAUSAJUDICIALNUMERO'] != wb_nueva_hoja['ID_OPERATIVO']).sum()\n",
    "# print(f\"\\nCasos procesados: {procesados}\")\n",
    "# print(f\"Casos sin cambios: {len(wb_nueva_hoja) - procesados}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
